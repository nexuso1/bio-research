{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10405,"status":"ok","timestamp":1700568150447,"user":{"displayName":"Samuel Fanči","userId":"10643939452898974935"},"user_tz":-60},"id":"wLIUpY0rj_J3","outputId":"43d44eb3-2921-426f-caf3-2cb60de59081"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":82,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36858,"status":"ok","timestamp":1700568187299,"user":{"displayName":"Samuel Fanči","userId":"10643939452898974935"},"user_tz":-60},"id":"wyRdzGfXkZ2j","outputId":"b5f96b95-416e-474d-951b-ef12848d206d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: biopython in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.81)Note: you may need to restart the kernel to use updated packages.\n","\n","Requirement already satisfied: transformers in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.35.0)\n","Collecting datasets\n","  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n","Collecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: numpy in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from biopython) (1.24.3)\n","Requirement already satisfied: filelock in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.12.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.17.3)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.10.3)\n","Requirement already satisfied: requests in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.14.1)\n","Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.1)\n","Collecting pyarrow>=8.0.0 (from datasets)\n","  Downloading pyarrow-14.0.1-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n","Collecting pyarrow-hotfix (from datasets)\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: pandas in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.1.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n","Collecting aiohttp (from datasets)\n","  Downloading aiohttp-3.9.0-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n","Collecting responses<0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting attrs>=17.3.0 (from aiohttp->datasets)\n","  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n","     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n","     ---------------------------------------- 61.2/61.2 kB 3.4 MB/s eta 0:00:00\n","Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n","  Downloading multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n","  Downloading yarl-1.9.3-cp311-cp311-win_amd64.whl.metadata (29 kB)\n","Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n","  Downloading frozenlist-1.4.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n","Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.0.5)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.7.22)\n","INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.0-cp311-none-win_amd64.whl.metadata (6.8 kB)\n","Collecting evaluate\n","  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n","     ---------------------------------------- 0.0/81.4 kB ? eta -:--:--\n","     ---------------------------------------- 81.4/81.4 kB 4.4 MB/s eta 0:00:00\n","  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n","     ---------------------------------------- 0.0/72.9 kB ? eta -:--:--\n","     ---------------------------------------- 72.9/72.9 kB 3.9 MB/s eta 0:00:00\n","  Downloading evaluate-0.2.2-py3-none-any.whl (69 kB)\n","     ---------------------------------------- 0.0/69.8 kB ? eta -:--:--\n","     ---------------------------------------- 69.8/69.8 kB 4.0 MB/s eta 0:00:00\n","INFO: pip is still looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n","  Downloading evaluate-0.2.1-py3-none-any.whl (69 kB)\n","     ---------------------------------------- 0.0/69.6 kB ? eta -:--:--\n","     ---------------------------------------- 69.6/69.6 kB 4.0 MB/s eta 0:00:00\n","  Downloading evaluate-0.2.0-py3-none-any.whl (69 kB)\n","     ---------------------------------------- 0.0/69.6 kB ? eta -:--:--\n","     ---------------------------------------- 69.6/69.6 kB 4.0 MB/s eta 0:00:00\n","  Downloading evaluate-0.1.2-py3-none-any.whl (53 kB)\n","     ---------------------------------------- 0.0/53.7 kB ? eta -:--:--\n","     ---------------------------------------- 53.7/53.7 kB 2.9 MB/s eta 0:00:00\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading evaluate-0.1.1-py3-none-any.whl (68 kB)\n","     ---------------------------------------- 0.0/68.8 kB ? eta -:--:--\n","     ---------------------------------------- 68.8/68.8 kB 3.9 MB/s eta 0:00:00\n","  Downloading evaluate-0.1.0-py3-none-any.whl (68 kB)\n","     ---------------------------------------- 0.0/68.7 kB ? eta -:--:--\n","     ---------------------------------------- 68.7/68.7 kB 1.8 MB/s eta 0:00:00\n","Collecting datasets\n","  Downloading datasets-2.14.7-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: colorama in c:\\users\\samo\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in c:\\users\\samo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n","   ---------------------------------------- 0.0/520.4 kB ? eta -:--:--\n","   -------------------------- ------------ 358.4/520.4 kB 10.9 MB/s eta 0:00:01\n","   ---------------------------------------- 520.4/520.4 kB 8.1 MB/s eta 0:00:00\n","Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","   ---------------------------------------- 0.0/84.1 kB ? eta -:--:--\n","   ---------------------------------------- 84.1/84.1 kB 4.6 MB/s eta 0:00:00\n","Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","   ---------------------------------------- 0.0/115.3 kB ? eta -:--:--\n","   ---------------------------------------- 115.3/115.3 kB 6.6 MB/s eta 0:00:00\n","Downloading aiohttp-3.9.0-cp311-cp311-win_amd64.whl (364 kB)\n","   ---------------------------------------- 0.0/364.3 kB ? eta -:--:--\n","   ---------------------------------------  358.4/364.3 kB 7.4 MB/s eta 0:00:01\n","   ---------------------------------------- 364.3/364.3 kB 5.7 MB/s eta 0:00:00\n","Downloading pyarrow-14.0.1-cp311-cp311-win_amd64.whl (24.6 MB)\n","   ---------------------------------------- 0.0/24.6 MB ? eta -:--:--\n","   ---------------------------------------- 0.3/24.6 MB 8.9 MB/s eta 0:00:03\n","   - -------------------------------------- 0.7/24.6 MB 8.5 MB/s eta 0:00:03\n","   - -------------------------------------- 1.1/24.6 MB 8.8 MB/s eta 0:00:03\n","   -- ------------------------------------- 1.5/24.6 MB 8.5 MB/s eta 0:00:03\n","   --- ------------------------------------ 1.8/24.6 MB 8.4 MB/s eta 0:00:03\n","   --- ------------------------------------ 2.2/24.6 MB 8.4 MB/s eta 0:00:03\n","   ---- ----------------------------------- 2.7/24.6 MB 8.5 MB/s eta 0:00:03\n","   ---- ----------------------------------- 3.0/24.6 MB 8.4 MB/s eta 0:00:03\n","   ----- ---------------------------------- 3.4/24.6 MB 8.4 MB/s eta 0:00:03\n","   ------ --------------------------------- 3.8/24.6 MB 8.3 MB/s eta 0:00:03\n","   ------ --------------------------------- 4.2/24.6 MB 8.4 MB/s eta 0:00:03\n","   ------- -------------------------------- 4.6/24.6 MB 8.4 MB/s eta 0:00:03\n","   -------- ------------------------------- 5.0/24.6 MB 8.4 MB/s eta 0:00:03\n","   -------- ------------------------------- 5.4/24.6 MB 8.4 MB/s eta 0:00:03\n","   --------- ------------------------------ 5.8/24.6 MB 8.5 MB/s eta 0:00:03\n","   ---------- ----------------------------- 6.2/24.6 MB 8.5 MB/s eta 0:00:03\n","   ---------- ----------------------------- 6.6/24.6 MB 8.5 MB/s eta 0:00:03\n","   ----------- ---------------------------- 7.0/24.6 MB 8.5 MB/s eta 0:00:03\n","   ------------ --------------------------- 7.4/24.6 MB 8.5 MB/s eta 0:00:03\n","   ------------ --------------------------- 7.8/24.6 MB 8.5 MB/s eta 0:00:02\n","   ------------- -------------------------- 8.2/24.6 MB 8.5 MB/s eta 0:00:02\n","   -------------- ------------------------- 8.6/24.6 MB 8.5 MB/s eta 0:00:02\n","   -------------- ------------------------- 9.0/24.6 MB 8.5 MB/s eta 0:00:02\n","   --------------- ------------------------ 9.4/24.6 MB 8.6 MB/s eta 0:00:02\n","   --------------- ------------------------ 9.8/24.6 MB 8.6 MB/s eta 0:00:02\n","   ---------------- ----------------------- 10.2/24.6 MB 8.6 MB/s eta 0:00:02\n","   ----------------- ---------------------- 10.6/24.6 MB 8.6 MB/s eta 0:00:02\n","   ----------------- ---------------------- 11.0/24.6 MB 8.6 MB/s eta 0:00:02\n","   ------------------ --------------------- 11.4/24.6 MB 8.5 MB/s eta 0:00:02\n","   ------------------- -------------------- 11.7/24.6 MB 8.5 MB/s eta 0:00:02\n","   ------------------- -------------------- 12.1/24.6 MB 8.5 MB/s eta 0:00:02\n","   -------------------- ------------------- 12.5/24.6 MB 8.5 MB/s eta 0:00:02\n","   --------------------- ------------------ 12.9/24.6 MB 8.5 MB/s eta 0:00:02\n","   --------------------- ------------------ 13.3/24.6 MB 8.5 MB/s eta 0:00:02\n","   ---------------------- ----------------- 13.7/24.6 MB 8.5 MB/s eta 0:00:02\n","   ---------------------- ----------------- 14.1/24.6 MB 8.5 MB/s eta 0:00:02\n","   ----------------------- ---------------- 14.4/24.6 MB 8.5 MB/s eta 0:00:02\n","   ------------------------ --------------- 14.8/24.6 MB 8.5 MB/s eta 0:00:02\n","   ------------------------ --------------- 15.2/24.6 MB 8.5 MB/s eta 0:00:02\n","   ------------------------- -------------- 15.6/24.6 MB 8.4 MB/s eta 0:00:02\n","   ------------------------- -------------- 15.9/24.6 MB 8.4 MB/s eta 0:00:02\n","   -------------------------- ------------- 16.3/24.6 MB 8.4 MB/s eta 0:00:01\n","   --------------------------- ------------ 16.7/24.6 MB 8.4 MB/s eta 0:00:01\n","   --------------------------- ------------ 17.0/24.6 MB 8.4 MB/s eta 0:00:01\n","   ---------------------------- ----------- 17.3/24.6 MB 8.4 MB/s eta 0:00:01\n","   ---------------------------- ----------- 17.7/24.6 MB 8.3 MB/s eta 0:00:01\n","   ----------------------------- ---------- 18.1/24.6 MB 8.3 MB/s eta 0:00:01\n","   ------------------------------ --------- 18.5/24.6 MB 8.3 MB/s eta 0:00:01\n","   ------------------------------ --------- 18.9/24.6 MB 8.3 MB/s eta 0:00:01\n","   ------------------------------- -------- 19.3/24.6 MB 8.3 MB/s eta 0:00:01\n","   ------------------------------- -------- 19.6/24.6 MB 8.3 MB/s eta 0:00:01\n","   -------------------------------- ------- 20.0/24.6 MB 8.3 MB/s eta 0:00:01\n","   --------------------------------- ------ 20.4/24.6 MB 8.2 MB/s eta 0:00:01\n","   --------------------------------- ------ 20.8/24.6 MB 8.2 MB/s eta 0:00:01\n","   ---------------------------------- ----- 21.2/24.6 MB 8.2 MB/s eta 0:00:01\n","   ----------------------------------- ---- 21.6/24.6 MB 8.2 MB/s eta 0:00:01\n","   ----------------------------------- ---- 22.0/24.6 MB 8.2 MB/s eta 0:00:01\n","   ------------------------------------ --- 22.4/24.6 MB 8.2 MB/s eta 0:00:01\n","   ------------------------------------- -- 22.8/24.6 MB 8.2 MB/s eta 0:00:01\n","   ------------------------------------- -- 23.2/24.6 MB 8.2 MB/s eta 0:00:01\n","   -------------------------------------- - 23.6/24.6 MB 8.3 MB/s eta 0:00:01\n","   ---------------------------------------  24.0/24.6 MB 8.3 MB/s eta 0:00:01\n","   ---------------------------------------  24.4/24.6 MB 8.4 MB/s eta 0:00:01\n","   ---------------------------------------  24.6/24.6 MB 8.3 MB/s eta 0:00:01\n","   ---------------------------------------  24.6/24.6 MB 8.3 MB/s eta 0:00:01\n","   ---------------------------------------  24.6/24.6 MB 8.3 MB/s eta 0:00:01\n","   ---------------------------------------- 24.6/24.6 MB 7.4 MB/s eta 0:00:00\n","Downloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n","   ---------------------------------------- 0.0/135.4 kB ? eta -:--:--\n","   ---------------------------------------- 135.4/135.4 kB 8.3 MB/s eta 0:00:00\n","Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Downloading xxhash-3.4.1-cp311-cp311-win_amd64.whl (29 kB)\n","Downloading frozenlist-1.4.0-cp311-cp311-win_amd64.whl (44 kB)\n","   ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n","   ---------------------------------------- 44.9/44.9 kB ? eta 0:00:00\n","Downloading yarl-1.9.3-cp311-cp311-win_amd64.whl (75 kB)\n","   ---------------------------------------- 0.0/75.9 kB ? eta -:--:--\n","   ---------------------------------------- 75.9/75.9 kB 4.1 MB/s eta 0:00:00\n","Installing collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, frozenlist, dill, attrs, yarl, responses, multiprocess, aiosignal, aiohttp, datasets, evaluate\n","Successfully installed aiohttp-3.9.0 aiosignal-1.3.1 attrs-23.1.0 datasets-2.14.7 dill-0.3.7 evaluate-0.4.1 frozenlist-1.4.0 multidict-6.0.4 multiprocess-0.70.15 pyarrow-14.0.1 pyarrow-hotfix-0.6 responses-0.18.0 xxhash-3.4.1 yarl-1.9.3\n"]}],"source":["%pip install biopython transformers datasets evaluate"]},{"cell_type":"markdown","metadata":{"id":"00dY1kwaknvd"},"source":["# EPSD Dataset processing"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"mvTgPCRvkwGt"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from Bio import SeqIO"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"4mvhBjWBkltD"},"outputs":[],"source":["import numpy as np\n","def load_fasta(path : str):\n","    seq_iterator = SeqIO.parse(open(path), 'fasta')\n","    seq_dict = {}\n","    for seq in seq_iterator:\n","        # extract sequence id\n","        try:\n","            seq_id = seq.id.split('|')[0]\n","        except IndexError:\n","            # For some reason, some sequences do not contain uniprot ids, so skip them\n","            continue\n","        seq_dict[seq_id] = str(seq.seq)\n","\n","    return seq_dict\n","\n","def load_phospho(path : str):\n","    data = pd.read_csv(path, sep='\\t')\n","    data.index = data['EPSD ID']\n","    grouped = data.groupby(data['EPSD ID'])\n","\n","    res = {}\n","    for id, group in grouped:\n","        res[id] = group['Position'].to_list()\n","\n","    return res\n","\n","def get_inputs_outputs(fasta_path, phospho_path):\n","    fasta = load_fasta(fasta_path)\n","    phospho = load_phospho(phospho_path)\n","\n","    inputs = []\n","    targets = []\n","    for key in phospho.keys():\n","        inputs.append(fasta[key])\n","        targets.append(phospho[key])\n","\n","    return inputs, targets"]},{"cell_type":"markdown","metadata":{"id":"vu85rtonlIG1"},"source":["## Create a dataset class for training"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"qsU_alwzlHX1"},"outputs":[],"source":["import re\n","\n","class ProteinDataset(Dataset):\n","    def __init__(self,tokenizer, max_length,  \n","                 inputs : list = None,\n","                 targets : list = None,\n","                 fasta_path : str = None,\n","                 phospho_path : str = None,\n","                 verbose = 1\n","                 ) -> None:\n","        # Load from file if paths given\n","        if fasta_path and phospho_path:\n","            self.x, self.y = get_inputs_outputs(fasta_path, phospho_path)\n","        \n","        # Take input from given arrays\n","        else:\n","            if verbose > 0:\n","                if inputs is None:\n","                    \n","                    print('Warning: No input path given and the inputs parameter is None')\n","                \n","                if targets is None:\n","                    print('Warning: No targets given and the targets parameter is None')\n","\n","            self.x = inputs\n","            self.y = targets\n","\n","        self.verbose = verbose\n","        self.tokenizer = tokenizer\n","        self.max_len = max_length\n","\n","        self.prune_long_sequences()\n","\n","    def prune_long_sequences(self) -> None:\n","        \"\"\"\n","        Remove all sequences that are longer than self.max_len from the dataset.\n","        Updates the self.x and self.y attributes.\n","        \"\"\"\n","        keep_x = []\n","        keep_y = []\n","\n","        count = 0\n","\n","        for i in range(len(self.x)):\n","            if len(self.x[i]) > self.max_len:\n","                count += 1\n","                continue\n","\n","            keep_x.append(self.x[i])\n","            keep_y.append(self.y[i])\n","\n","        if self.verbose > 0:\n","            print(f\"Removed {count} sequences from the dataset longer than {self.max_len}.\")\n","\n","        self.x = keep_x\n","        self.y = keep_y\n","\n","    def prep_seq(self, seq):\n","        \"\"\"\n","        Prepares the given sequence for the model by subbing rare AAs for X and adding \n","        padding between AAs. Required by the base model.\n","        \"\"\"\n","        return \" \".join(list(re.sub(r\"[UZOB]\", \"X\", seq)))\n","\n","    def prep_target(self, enc, target):\n","        \"\"\"\n","        Transforms the target into an array of ones and zeros with the same length as the \n","        corresponding FASTA protein sequence. Value of one represents a phosphorylation \n","        site being present at the i-th AA in the protein sequence.\n","        \"\"\"\n","        res = torch.zeros(self.max_len).long()\n","        res[target] = 1\n","        res = res.roll(1)\n","        for i, idx in enumerate(enc.input_ids.flatten().int()):\n","            if idx == 0: # [PAD]\n","                break\n","\n","            if idx == 2 or idx == 3: # [CLS] or [SEP]\n","                res[i] = -100 # This label will be ignored by the loss\n","        return res\n","\n","    def __getitem__(self, index):\n","        seq = self.x[index]\n","        target =self.y[index]\n","        seq = self.prep_seq(seq)\n","        encoding = self.tokenizer(\n","            seq,\n","            add_special_tokens=True,\n","            max_length = self.max_len,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","\n","        target = self.prep_target(encoding, target)\n","        return {\n","            'input_ids' : encoding['input_ids'].flatten(),\n","            'attention_mask' : encoding['attention_mask'].flatten(),\n","            'labels' : target\n","        }\n","\n","    def __len__(self):\n","        return len(self.x)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1700568259808,"user":{"displayName":"Samuel Fanči","userId":"10643939452898974935"},"user_tz":-60},"id":"FjHGHsAelxKd","outputId":"71e91b31-b408-42cc-8b45-f61525e2fbc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cpu\n"]}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(\"Using {}\".format(device))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"x6HtBfWK34ob"},"outputs":[],"source":["#import dependencies\n","import os.path\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n","from torch.utils.data import DataLoader\n","\n","import re\n","import numpy as np\n","import pandas as pd\n","import copy\n","\n","import transformers\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","from transformers.models.t5.modeling_t5 import T5Config, T5PreTrainedModel, T5Stack\n","from transformers.utils.model_parallel_utils import assert_device_map, get_device_map\n","from transformers import T5EncoderModel, T5Tokenizer\n","from transformers import TrainingArguments, Trainer, set_seed\n","\n","# from evaluate import load\n","# from datasets import Dataset\n","\n","from tqdm import tqdm\n","import random\n","\n","from scipy import stats\n","from sklearn.metrics import accuracy_score\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"ho0d36DW3NFc"},"source":["## LoRA implementation\n","taken from https://github.com/r-three/t-few\n","\n","(https://github.com/r-three/t-few/blob/master/src/models/lora.py, https://github.com/r-three/t-few/tree/master/configs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8u92yr7Z3MRN"},"outputs":[],"source":["# Modifies an existing transformer and introduce the LoRA layers\n","\n","class LoRAConfig:\n","    def __init__(self):\n","        self.lora_rank = 4\n","        self.lora_init_scale = 0.01\n","        self.lora_modules = \".*SelfAttention|.*EncDecAttention\"\n","        self.lora_layers = \"q|k|v|o\"\n","        self.trainable_param_names = \".*layer_norm.*|.*lora_[ab].*\"\n","        self.lora_scaling_rank = 1\n","        # lora_modules and lora_layers are speicified with regular expressions\n","        # see https://www.w3schools.com/python/python_regex.asp for reference\n","\n","class LoRALinear(nn.Module):\n","    def __init__(self, linear_layer, rank, scaling_rank, init_scale):\n","        super().__init__()\n","        self.in_features = linear_layer.in_features\n","        self.out_features = linear_layer.out_features\n","        self.rank = rank\n","        self.scaling_rank = scaling_rank\n","        self.weight = linear_layer.weight\n","        self.bias = linear_layer.bias\n","        if self.rank > 0:\n","            self.lora_a = nn.Parameter(torch.randn(rank, linear_layer.in_features) * init_scale)\n","            if init_scale < 0:\n","                self.lora_b = nn.Parameter(torch.randn(linear_layer.out_features, rank) * init_scale)\n","            else:\n","                self.lora_b = nn.Parameter(torch.zeros(linear_layer.out_features, rank))\n","        if self.scaling_rank:\n","            self.multi_lora_a = nn.Parameter(\n","                torch.ones(self.scaling_rank, linear_layer.in_features)\n","                + torch.randn(self.scaling_rank, linear_layer.in_features) * init_scale\n","            )\n","            if init_scale < 0:\n","                self.multi_lora_b = nn.Parameter(\n","                    torch.ones(linear_layer.out_features, self.scaling_rank)\n","                    + torch.randn(linear_layer.out_features, self.scaling_rank) * init_scale\n","                )\n","            else:\n","                self.multi_lora_b = nn.Parameter(torch.ones(linear_layer.out_features, self.scaling_rank))\n","\n","    def forward(self, input):\n","        if self.scaling_rank == 1 and self.rank == 0:\n","            # parsimonious implementation for ia3 and lora scaling\n","            if self.multi_lora_a.requires_grad:\n","                hidden = F.linear((input * self.multi_lora_a.flatten()), self.weight, self.bias)\n","            else:\n","                hidden = F.linear(input, self.weight, self.bias)\n","            if self.multi_lora_b.requires_grad:\n","                hidden = hidden * self.multi_lora_b.flatten()\n","            return hidden\n","        else:\n","            # general implementation for lora (adding and scaling)\n","            weight = self.weight\n","            if self.scaling_rank:\n","                weight = weight * torch.matmul(self.multi_lora_b, self.multi_lora_a) / self.scaling_rank\n","            if self.rank:\n","                weight = weight + torch.matmul(self.lora_b, self.lora_a) / self.rank\n","            return F.linear(input, weight, self.bias)\n","\n","    def extra_repr(self):\n","        return \"in_features={}, out_features={}, bias={}, rank={}, scaling_rank={}\".format(\n","            self.in_features, self.out_features, self.bias is not None, self.rank, self.scaling_rank\n","        )\n","\n","\n","def modify_with_lora(transformer, config):\n","    for m_name, module in dict(transformer.named_modules()).items():\n","        if re.fullmatch(config.lora_modules, m_name):\n","            for c_name, layer in dict(module.named_children()).items():\n","                if re.fullmatch(config.lora_layers, c_name):\n","                    assert isinstance(\n","                        layer, nn.Linear\n","                    ), f\"LoRA can only be applied to torch.nn.Linear, but {layer} is {type(layer)}.\"\n","                    setattr(\n","                        module,\n","                        c_name,\n","                        LoRALinear(layer, config.lora_rank, config.lora_scaling_rank, config.lora_init_scale),\n","                    )\n","    return transformer"]},{"cell_type":"markdown","metadata":{"id":"O3YXT5Le3YZV"},"source":["# Classification/Regression heads\n","\n","taken from https://github.com/agemagician/ProtTrans/blob/master/Fine-Tuning/PT5_LoRA_Finetuning_per_prot.ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wY0YEXQM3kLM"},"outputs":[],"source":["class ClassConfig:\n","    def __init__(self, dropout=0.2, num_labels=1):\n","        self.dropout_rate = dropout\n","        self.num_labels = num_labels\n","\n","class T5EncoderClassificationHead(nn.Module):\n","    \"\"\"Head for sentence-level classification tasks.\"\"\"\n","\n","    def __init__(self, config, class_config):\n","        super().__init__()\n","        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n","        self.dropout = nn.Dropout(class_config.dropout_rate)\n","        self.out_proj = nn.Linear(config.hidden_size, class_config.num_labels)\n","\n","    def forward(self, hidden_states):\n","\n","        hidden_states =  torch.mean(hidden_states,dim=1)  # avg embedding\n","\n","        hidden_states = self.dropout(hidden_states)\n","        hidden_states = self.dense(hidden_states)\n","        hidden_states = torch.tanh(hidden_states)\n","        hidden_states = self.dropout(hidden_states)\n","        hidden_states = self.out_proj(hidden_states)\n","        return hidden_states\n","\n","class T5EncoderForSimpleSequenceClassification(T5PreTrainedModel):\n","\n","    def __init__(self, config: T5Config, class_config):\n","        super().__init__(config)\n","        self.num_labels = class_config.num_labels\n","        self.config = config\n","\n","        self.shared = nn.Embedding(config.vocab_size, config.d_model)\n","\n","        encoder_config = copy.deepcopy(config)\n","        encoder_config.use_cache = False\n","        encoder_config.is_encoder_decoder = False\n","        self.encoder = T5Stack(encoder_config, self.shared)\n","\n","        self.dropout = nn.Dropout(class_config.dropout_rate)\n","        self.classifier = T5EncoderClassificationHead(config, class_config)\n","\n","        # Initialize weights and apply final processing\n","        self.post_init()\n","\n","        # Model parallel\n","        self.model_parallel = False\n","        self.device_map = None\n","\n","    def parallelize(self, device_map=None):\n","        self.device_map = (\n","            get_device_map(len(self.encoder.block), range(torch.cuda.device_count()))\n","            if device_map is None\n","            else device_map\n","        )\n","        assert_device_map(self.device_map, len(self.encoder.block))\n","        self.encoder.parallelize(self.device_map)\n","        self.classifier = self.classifier.to(self.encoder.first_device)\n","        self.model_parallel = True\n","\n","    def deparallelize(self):\n","        self.encoder.deparallelize()\n","        self.encoder = self.encoder.to(\"cpu\")\n","        self.model_parallel = False\n","        self.device_map = None\n","        torch.cuda.empty_cache()\n","\n","    def get_input_embeddings(self):\n","        return self.shared\n","\n","    def set_input_embeddings(self, new_embeddings):\n","        self.shared = new_embeddings\n","        self.encoder.set_input_embeddings(new_embeddings)\n","\n","    def get_encoder(self):\n","        return self.encoder\n","\n","    def _prune_heads(self, heads_to_prune):\n","        \"\"\"\n","        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n","        class PreTrainedModel\n","        \"\"\"\n","        for layer, heads in heads_to_prune.items():\n","            self.encoder.layer[layer].attention.prune_heads(heads)\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        outputs = self.encoder(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            inputs_embeds=inputs_embeds,\n","            head_mask=head_mask,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        hidden_states = outputs[0]\n","        logits = self.classifier(hidden_states)\n","\n","        loss = None\n","        if labels is not None:\n","            if self.config.problem_type is None:\n","                if self.num_labels == 1:\n","                    self.config.problem_type = \"regression\"\n","                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n","                    self.config.problem_type = \"single_label_classification\"\n","                else:\n","                    self.config.problem_type = \"multi_label_classification\"\n","\n","            if self.config.problem_type == \"regression\":\n","                loss_fct = MSELoss()\n","                if self.num_labels == 1:\n","                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n","                else:\n","                    loss = loss_fct(logits, labels)\n","            elif self.config.problem_type == \"single_label_classification\":\n","                loss_fct = CrossEntropyLoss()\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","            elif self.config.problem_type == \"multi_label_classification\":\n","                loss_fct = BCEWithLogitsLoss()\n","                loss = loss_fct(logits, labels)\n","        if not return_dict:\n","            output = (logits,) + outputs[1:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return SequenceClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )"]},{"cell_type":"markdown","metadata":{"id":"B9tCzXhX4awZ"},"source":["# Modified ProtT5 model\n","\n","taken from https://github.com/agemagician/ProtTrans/blob/master/Fine-Tuning/PT5_LoRA_Finetuning_per_prot.ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V55DbSt64ZTN"},"outputs":[],"source":["def PT5_classification_model(num_labels):\n","    # Load PT5 and tokenizer\n","    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\")\n","    tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\")\n","\n","    # Create new Classifier model with PT5 dimensions\n","    class_config=ClassConfig(num_labels=num_labels)\n","    class_model=T5EncoderForSimpleSequenceClassification(model.config,class_config)\n","\n","    # Set encoder and embedding weights to checkpoint weights\n","    class_model.shared=model.shared\n","    class_model.encoder=model.encoder\n","\n","    # Delete the checkpoint model\n","    model=class_model\n","    del class_model\n","\n","    # Print number of trainable parameters\n","    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","    params = sum([np.prod(p.size()) for p in model_parameters])\n","    print(\"ProtT5_Classfier\\nTrainable Parameter: \"+ str(params))\n","\n","    # Add model modification lora\n","    config = LoRAConfig()\n","\n","    # Add LoRA layers\n","    model = modify_with_lora(model, config)\n","\n","    # Freeze Embeddings and Encoder (except LoRA)\n","    for (param_name, param) in model.shared.named_parameters():\n","                param.requires_grad = False\n","    for (param_name, param) in model.encoder.named_parameters():\n","                param.requires_grad = False\n","\n","    for (param_name, param) in model.named_parameters():\n","            if re.fullmatch(config.trainable_param_names, param_name):\n","                param.requires_grad = True\n","\n","    # Print trainable Parameter\n","    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","    params = sum([np.prod(p.size()) for p in model_parameters])\n","    print(\"ProtT5_LoRA_Classfier\\nTrainable Parameter: \"+ str(params) + \"\\n\")\n","\n","    return model, tokenizer"]},{"cell_type":"markdown","metadata":{"id":"eq_gQ-cn4z5g"},"source":["# DeepSpeed config\n","\n","taken from https://github.com/agemagician/ProtTrans/blob/master/Fine-Tuning/PT5_LoRA_Finetuning_per_prot.ipynb"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"lrneiMti42Sj"},"outputs":[],"source":["# Deepspeed config for optimizer CPU offload\n","\n","ds_config = {\n","    \"fp16\": {\n","        \"enabled\": \"auto\",\n","        \"loss_scale\": 0,\n","        \"loss_scale_window\": 1000,\n","        \"initial_scale_power\": 16,\n","        \"hysteresis\": 2,\n","        \"min_loss_scale\": 1\n","    },\n","\n","    \"optimizer\": {\n","        \"type\": \"AdamW\",\n","        \"params\": {\n","            \"lr\": \"auto\",\n","            \"betas\": \"auto\",\n","            \"eps\": \"auto\",\n","            \"weight_decay\": \"auto\"\n","        }\n","    },\n","\n","    \"scheduler\": {\n","        \"type\": \"WarmupLR\",\n","        \"params\": {\n","            \"warmup_min_lr\": \"auto\",\n","            \"warmup_max_lr\": \"auto\",\n","            \"warmup_num_steps\": \"auto\"\n","        }\n","    },\n","\n","    \"zero_optimization\": {\n","        \"stage\": 2,\n","        \"offload_optimizer\": {\n","            \"device\": \"cpu\",\n","            \"pin_memory\": True\n","        },\n","        \"allgather_partitions\": True,\n","        \"allgather_bucket_size\": 2e8,\n","        \"overlap_comm\": True,\n","        \"reduce_scatter\": True,\n","        \"reduce_bucket_size\": 2e8,\n","        \"contiguous_gradients\": True\n","    },\n","\n","    \"gradient_accumulation_steps\": \"auto\",\n","    \"gradient_clipping\": \"auto\",\n","    \"steps_per_print\": 2000,\n","    \"train_batch_size\": \"auto\",\n","    \"train_micro_batch_size_per_gpu\": \"auto\",\n","    \"wall_clock_breakdown\": False\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGShfCNl6oMF"},"outputs":[],"source":["def preprocess_sequences(seqs, df=True):\n","    # this will replace all rare/ambiguous amino acids by X and introduce white-space between all amino acids (PT5 needs this)\n","    if df:\n","      return df.str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n","    else:\n","      return [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence))) for sequence in seqs]"]},{"cell_type":"markdown","metadata":{"id":"phuS7xmr6pX9"},"source":["## Train functions\n","taken from https://github.com/agemagician/ProtTrans/blob/master/Fine-Tuning/PT5_LoRA_Finetuning_per_prot.ipynb"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"3h0mXT7P5Yv2"},"outputs":[],"source":["# Set random seeds for reproducibility of your trainings run\n","def set_seeds(s):\n","    torch.manual_seed(s)\n","    np.random.seed(s)\n","    random.seed(s)\n","    set_seed(s)\n","\n","# Main training fuction\n","def train_per_protein(\n","        train_df,         #training data\n","        valid_df,         #validation data\n","        num_labels= 1,    #1 for regression, >1 for classification\n","\n","        # effective training batch size is batch * accum\n","        # we recommend an effective batch size of 8\n","        batch= 4,         #for training\n","        accum= 2,         #gradient accumulation\n","\n","        val_batch = 16,   #batch size for evaluation\n","        epochs= 10,       #training epochs\n","        lr= 3e-4,         #recommended learning rate\n","        seed= 42,         #random seed\n","        deepspeed= True,  #if gpu is large enough disable deepspeed for training speedup\n","        gpu= 1 ):         #gpu selection (1 for first gpu)\n","\n","    # Set gpu device\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu-1)\n","\n","    # Set all random seeds\n","    set_seeds(seed)\n","\n","    # load model\n","    model, tokenizer = PT5_classification_model(num_labels=num_labels)\n","\n","    # Preprocess inputs\n","    # Replace uncommon AAs with \"X\"\n","    train_df[\"sequence\"]=preprocess_sequences(train_df['sequence'])\n","    valid_df[\"sequence\"]=valid_df[\"sequence\"].str.replace('|'.join([\"O\",\"B\",\"U\",\"Z\"]),\"X\",regex=True)\n","    # Add spaces between each amino acid for PT5 to correctly use them\n","    train_df['sequence']=train_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n","    valid_df['sequence']=valid_df.apply(lambda row : \" \".join(row[\"sequence\"]), axis = 1)\n","\n","    # Create Datasets\n","    train_set=create_dataset(tokenizer,list(train_df['sequence']),list(train_df['label']))\n","    valid_set=create_dataset(tokenizer,list(valid_df['sequence']),list(valid_df['label']))\n","\n","    # Huggingface Trainer arguments\n","    args = TrainingArguments(\n","        \"./\",\n","        evaluation_strategy = \"epoch\",\n","        logging_strategy = \"epoch\",\n","        save_strategy = \"no\",\n","        learning_rate=lr,\n","        per_device_train_batch_size=batch,\n","        per_device_eval_batch_size=val_batch,\n","        gradient_accumulation_steps=accum,\n","        num_train_epochs=epochs,\n","        seed = seed,\n","        deepspeed= ds_config if deepspeed else None,\n","    )\n","\n","    # Metric definition for validation data\n","    def compute_metrics(eval_pred):\n","        if num_labels>1:  # for classification\n","            metric = load(\"accuracy\")\n","            predictions, labels = eval_pred\n","            predictions = np.argmax(predictions, axis=1)\n","        else:  # for regression\n","            metric = load(\"spearmanr\")\n","            predictions, labels = eval_pred\n","\n","        return metric.compute(predictions=predictions, references=labels)\n","\n","    # Trainer\n","    trainer = Trainer(\n","        model,\n","        args,\n","        train_dataset=train_set,\n","        eval_dataset=valid_set,\n","        tokenizer=tokenizer,\n","        compute_metrics=compute_metrics\n","    )\n","\n","    # Train model\n","    trainer.train()\n","\n","    return tokenizer, model, trainer.state.log_history"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12683,"status":"ok","timestamp":1699912561260,"user":{"displayName":"Samuel Fanči","userId":"10643939452898974935"},"user_tz":-60},"id":"RJM8rFvglHUw","outputId":"54409fde-38b9-495e-f66b-2f98202b5784"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at Rostlab/prot_bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import BertForTokenClassification, BertTokenizer\n","\n","pbert = BertForTokenClassification.from_pretrained(\"Rostlab/prot_bert\")\n","pbert.config.num_labels = 2\n","tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1433,"status":"ok","timestamp":1699913407233,"user":{"displayName":"Samuel Fanči","userId":"10643939452898974935"},"user_tz":-60},"id":"VwgyETE6toxa","outputId":"1a3bc9fb-fc82-4428-b80a-8a2fe449ee47"},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([[ 6,  9, 15, 23, 28,  6, 29]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["example = ['A E T C Z A O']\n","enc = tokenizer(example, return_tensors='pt', add_special_tokens=False)\n","enc"]},{"cell_type":"markdown","metadata":{"id":"lr36GX3t4-fK"},"source":["# TODO: Custom protein embedding"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":249,"status":"ok","timestamp":1700572271818,"user":{"displayName":"Samuel Fanči","userId":"10643939452898974935"},"user_tz":-60},"id":"z4I9yJLg9Bud"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from transformers import BertModel, BertTokenizer"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":232,"status":"ok","timestamp":1700572273358,"user":{"displayName":"Samuel Fanči","userId":"10643939452898974935"},"user_tz":-60},"id":"b6ekupXq9Dt9"},"outputs":[],"source":["def get_bert_model():\n","    pbert = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n","    pbert.config.num_labels = 2\n","    tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n","\n","    return pbert, tokenizer"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":25190,"status":"ok","timestamp":1700572299462,"user":{"displayName":"Samuel Fanči","userId":"10643939452898974935"},"user_tz":-60},"id":"2Ridi1FT9hdD"},"outputs":[],"source":["pbert, tokenizer = get_bert_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0-KlEq8CrBLz"},"outputs":[],"source":["next(pbert.parameters()).name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dEJmYV0N9q5Z"},"outputs":[],"source":["for p in pbert.parameters():\n","  if p.name and (p.name == 'classifier.weight' or p.name == 'classifier.bias'):\n","    continue\n","\n","  p.requires_grad = False"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"l6F7-hnJtASv"},"outputs":[],"source":["class ProteinEmbed(nn.Module):\n","    def __init__(self, base_model : nn.Module, dropout = 0.2, n_labels = 2, transfer_learning=True) -> None:\n","        super(ProteinEmbed, self).__init__()\n","        self.base = base_model\n","        self.n_labels = n_labels\n","        self.dropout = nn.Dropout(dropout)\n","        self.classifier = nn.Linear(self.base.config.hidden_size, self.n_labels)\n","        self.activation = F.softmax\n","        self.init_weights()\n","\n","        if transfer_learning:\n","            self.freeze_base()\n","\n","    def init_weights(self):\n","        torch.nn.init.normal_(self.classifier.weight)\n","        torch.nn.init.zeros_(self.classifier.bias)\n","        \n","    def freeze_base(self):\n","        for p in self.base.parameters():\n","          p.requires_grad = False\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","    ):\n","        out = self.base(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=True,\n","        )\n","\n","        sequence_output = out.hidden_states[-1]\n","        sequence_output = self.dropout(sequence_output)\n","        logits = self.classifier(sequence_output)\n","        outputs = self.activation(logits, -1)\n","\n","        if labels is not None:\n","            loss_fct = CrossEntropyLoss()\n","            # Only keep active parts of the loss\n","            if attention_mask is not None:\n","                active_loss = attention_mask.view(-1) == 1\n","                active_logits = logits.view(-1, self.n_labels)\n","                active_labels = torch.where(\n","                    active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n","                )\n","                loss = loss_fct(active_logits, active_labels)\n","            else:\n","                loss = loss_fct(logits.view(-1, self.n_labels), labels.view(-1))\n","            outputs = (loss, outputs)\n","\n","        return outputs  # (loss), scores, (hidden_states), (attentions)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'pbert' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Samo\\Repos\\bio-research\\colab_model.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test \u001b[39m=\u001b[39m ProteinEmbed(pbert)\n","\u001b[1;31mNameError\u001b[0m: name 'pbert' is not defined"]}],"source":["test = ProteinEmbed(pbert)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Samo\\AppData\\Local\\Temp\\ipykernel_20208\\2073962776.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  encoding['labels'] = torch.tensor(target, dtype=torch.long)\n"]},{"data":{"text/plain":["(tensor(3.3537, grad_fn=<NllLossBackward0>),\n"," tensor([[[1.1618e-09, 5.3341e-08],\n","          [8.2880e-08, 3.3738e-06],\n","          [9.0700e-07, 4.1019e-05],\n","          ...,\n","          [3.9450e-06, 1.1491e-03],\n","          [5.1033e-06, 1.7169e-03],\n","          [6.8030e-09, 1.4410e-07]]], grad_fn=<SoftmaxBackward0>))"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["test(output_hidden_states =True, **ds[0])"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":231,"status":"ok","timestamp":1700571604246,"user":{"displayName":"Samuel Fanči","userId":"10643939452898974935"},"user_tz":-60},"id":"SlEWat-ZlkVq"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","from sklearn.model_selection import train_test_split\n","import evaluate\n","\n","def set_seeds(s):\n","    torch.manual_seed(s)\n","    np.random.seed(s)\n","    random.seed(s)\n","    set_seed(s)\n","\n","def compute_metrics(eval_pred, metric):\n","    preds, labels = eval_pred\n","    return metric.compute(predictions = preds, references=labels)\n","\n","def train_model(train_ds, test_ds, model, tokenizer,\n","                lr=3e-4, epochs=1, batch=1, val_batch=1, accum=1, seed=42, deepspeed=None):\n","\n","    # Set all random seeds\n","    set_seeds(seed)\n","\n","    # Huggingface Trainer arguments\n","    args = TrainingArguments(\n","        \"./\",\n","        evaluation_strategy = \"epoch\",\n","        logging_strategy = \"epoch\",\n","        save_strategy = \"no\",\n","        learning_rate=lr,\n","        per_device_train_batch_size=batch,\n","        per_device_eval_batch_size=val_batch,\n","        gradient_accumulation_steps=accum,\n","        num_train_epochs=epochs,\n","        seed = seed,\n","        deepspeed= ds_config if deepspeed else None,\n","    )\n","    \n","    # Trainer\n","    trainer = Trainer(\n","        model,\n","        args,\n","        train_dataset=train_ds,\n","        eval_dataset=test_ds,\n","        compute_metrics=compute_metrics\n","    )\n","\n","    # Train model\n","    trainer.train()\n","\n","    return tokenizer, model, trainer.state.log_history"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Removed 3854 sequences from the dataset longer than 2048.\n","Removed 1311 sequences from the dataset longer than 2048.\n"]}],"source":["inputs, outputs = get_inputs_outputs('epsd_sequences/Total.fasta', 'epsd_sequences/Total.txt')\n","pbert, tokenizer = get_bert_model()\n","model = ProteinEmbed(pbert)\n","train_X, test_X, train_y, test_y = train_test_split(inputs, outputs, random_state=42)\n","\n","train_dataset = ProteinDataset(tokenizer=tokenizer, max_length=2048, inputs=train_X, targets=train_y)\n","test_dataset = ProteinDataset(tokenizer=tokenizer, max_length=2048, inputs=test_X, targets=test_y)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["model = ProteinEmbed(pbert)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([ 2, 21, 14,  ...,  0,  0,  0]),\n"," 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]),\n"," 'labels': tensor([-100,    0,    0,  ...,    0,    0,    0])}"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset[0]"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 2/153140 [00:50<1093:32:50, 25.71s/it]"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Samo\\Repos\\bio-research\\colab_model.ipynb Cell 37\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_model(train_ds\u001b[39m=\u001b[39;49mtrain_dataset, test_ds\u001b[39m=\u001b[39;49mtest_dataset, model\u001b[39m=\u001b[39;49mmodel, tokenizer\u001b[39m=\u001b[39;49mtokenizer, seed\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n","\u001b[1;32mc:\\Users\\Samo\\Repos\\bio-research\\colab_model.ipynb Cell 37\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     model,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tokenizer, model, trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mlog_history\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1553\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1555\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1556\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1557\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1558\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1560\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:1860\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1857\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m   1859\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1860\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1862\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1863\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1864\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1865\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1866\u001b[0m ):\n\u001b[0;32m   1867\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2725\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2722\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   2724\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2725\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[0;32m   2727\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2728\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2748\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2746\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2747\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2748\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[0;32m   2749\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2750\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2751\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","\u001b[1;32mc:\\Users\\Samo\\Repos\\bio-research\\colab_model.ipynb Cell 37\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     input_ids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m ):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         input_ids,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     sequence_output \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mhidden_states[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X52sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     sequence_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(sequence_output)\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1006\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m   1007\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1008\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1012\u001b[0m )\n\u001b[1;32m-> 1013\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1014\u001b[0m     embedding_output,\n\u001b[0;32m   1015\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1016\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1017\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1018\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1019\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1020\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1021\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1022\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1023\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1024\u001b[0m )\n\u001b[0;32m   1025\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1026\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    596\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    597\u001b[0m         layer_module\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[0;32m    598\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m         output_attentions,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    608\u001b[0m         hidden_states,\n\u001b[0;32m    609\u001b[0m         attention_mask,\n\u001b[0;32m    610\u001b[0m         layer_head_mask,\n\u001b[0;32m    611\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    612\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    613\u001b[0m         past_key_value,\n\u001b[0;32m    614\u001b[0m         output_attentions,\n\u001b[0;32m    615\u001b[0m     )\n\u001b[0;32m    617\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    618\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    536\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    537\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 539\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    540\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[0;32m    541\u001b[0m )\n\u001b[0;32m    542\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[0;32m    544\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pytorch_utils.py:241\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 241\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:551\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[1;32m--> 551\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[0;32m    552\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    553\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:452\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m    451\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[1;32m--> 452\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate_act_fn(hidden_states)\n\u001b[0;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\activations.py:78\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mact(\u001b[39minput\u001b[39;49m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train_model(train_ds=train_dataset, test_ds=test_dataset, model=model, tokenizer=tokenizer, seed=42)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["def main(**kwargs):\n","    inputs, outputs = get_inputs_outputs('epsd_sequences/Total.fasta', 'epsd_sequences/Total.txt')\n","    pbert, tokenizer = get_bert_model()\n","    model = ProteinEmbed(pbert)\n","    train_X, test_X, train_y, test_y = train_test_split(inputs, outputs, random_state=kwargs['seed'])\n","\n","    train_dataset = ProteinDataset(tokenizer=tokenizer, max_length=kwargs['max_length'], inputs=train_X, targets=train_y)\n","    test_dataset = ProteinDataset(tokenizer=tokenizer, max_length=kwargs['max_length'], inputs=test_X, targets=test_y)\n","\n","    train_model(train_ds=train_dataset, test_ds=test_dataset, model=model, tokenizer=tokenizer, seed=kwargs['seed'])"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/3063 [07:56<?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Removed 5171 sequences from the dataset longer than 2047.\n"]}],"source":["inputs, outputs = get_inputs_outputs('epsd_sequences/Total.fasta', 'epsd_sequences/Total.txt')\n","ds = ProteinDataset(tokenizer=tokenizer, max_length=2047, inputs=inputs, targets=outputs)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/plain":["('M L N S V I K R S A L C R F K F T C L Q V S E C R P A Q I E I S K R L Y S A K A S G N G E Y D L C V I G G G P G G Y V A A I R G A Q L G L K T I C V E K R G T L G G T C L N V G C I P S K A L L N N S H I Y H T V K H D T K R R G I D V S G V S V N L S Q M M K A K D D S V K S L T S G I E Y L F K K N K V E Y A K G T G S F I D P Q T L S V K G I D G A A D Q T I K A K N F I I A T G S E V K P F P G V T I D E K K I V S S T G A L S L S E V P K K M T V L G G G I I G L E M G S V W S R L G A E V T V V E F L P A V G G P M D A D I S K A L S R I I S K Q G I K F K T S T K L L S A K V N G D S V E V E I E N M K N N K R E T Y Q T D V L L V A I G R V P Y T E G L G L D K L G I S M D K S N R V I M D S E Y R T N I P H I R V I G D A T L G P M L A H K A E D E G I A A V E Y I A K G Q G H V N Y N C I P A V M Y T H P E V A W V G I T E Q K A K E S G I K Y R I G T F P F S A N S R A K T N M D A D G L V K V I V D A E T D R L L G V H M I G P M A G E L I G E A T L A L E Y G A S A E D V A R V C H A H P T L S E A T K E A M M A A W C G K S I H F',\n"," tensor([-100.,    0.,    0.,  ...,    0.,    0.,    0.]))"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["ds[0]"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Removed 3854 sequences from the dataset longer than 2048.\n","Removed 1311 sequences from the dataset longer than 2048.\n"]},{"name":"stderr","output_type":"stream","text":[]},{"ename":"AttributeError","evalue":"'list' object has no attribute 'keys'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Samo\\Repos\\bio-research\\colab_model.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m main(max_length\u001b[39m=\u001b[39;49m \u001b[39m2048\u001b[39;49m, seed \u001b[39m=\u001b[39;49m \u001b[39m42\u001b[39;49m)\n","\u001b[1;32mc:\\Users\\Samo\\Repos\\bio-research\\colab_model.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X50sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m ProteinDataset(tokenizer\u001b[39m=\u001b[39mtokenizer, max_length\u001b[39m=\u001b[39mkwargs[\u001b[39m'\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m'\u001b[39m], inputs\u001b[39m=\u001b[39mtrain_X, targets\u001b[39m=\u001b[39mtrain_y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m ProteinDataset(tokenizer\u001b[39m=\u001b[39mtokenizer, max_length\u001b[39m=\u001b[39mkwargs[\u001b[39m'\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m'\u001b[39m], inputs\u001b[39m=\u001b[39mtest_X, targets\u001b[39m=\u001b[39mtest_y)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X50sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m train_model(train_ds\u001b[39m=\u001b[39;49mtrain_dataset, test_ds\u001b[39m=\u001b[39;49mtest_dataset, model\u001b[39m=\u001b[39;49mmodel, tokenizer\u001b[39m=\u001b[39;49mtokenizer, seed\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m'\u001b[39;49m])\n","\u001b[1;32mc:\\Users\\Samo\\Repos\\bio-research\\colab_model.ipynb Cell 36\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X50sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X50sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     model,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X50sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X50sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X50sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X50sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X50sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samo/Repos/bio-research/colab_model.ipynb#X50sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tokenizer, model, trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mlog_history\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1553\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1555\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1556\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1557\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1558\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1560\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:1838\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1835\u001b[0m     rng_to_sync \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1837\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m-> 1838\u001b[0m \u001b[39mfor\u001b[39;49;00m step, inputs \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(epoch_iterator):\n\u001b[0;32m   1839\u001b[0m     total_batched_samples \u001b[39m+\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m\n\u001b[0;32m   1840\u001b[0m     \u001b[39mif\u001b[39;49;00m rng_to_sync:\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\data_loader.py:451\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m     current_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(dataloader_iter)\n\u001b[0;32m    452\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m     \u001b[39myield\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer_utils.py:755\u001b[0m, in \u001b[0;36mRemoveColumnsCollator.__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, features: List[\u001b[39mdict\u001b[39m]):\n\u001b[0;32m    754\u001b[0m     features \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remove_columns(feature) \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m features]\n\u001b[1;32m--> 755\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_collator(features)\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\data\\data_collator.py:249\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, features: List[Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m--> 249\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mpad(\n\u001b[0;32m    250\u001b[0m         features,\n\u001b[0;32m    251\u001b[0m         padding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding,\n\u001b[0;32m    252\u001b[0m         max_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_length,\n\u001b[0;32m    253\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad_to_multiple_of,\n\u001b[0;32m    254\u001b[0m         return_tensors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_tensors,\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m batch:\n\u001b[0;32m    257\u001b[0m         batch[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n","File \u001b[1;32mc:\\Users\\Samo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3216\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[1;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[0;32m   3212\u001b[0m \u001b[39m# The model's main input name, usually `input_ids`, has be passed for padding\u001b[39;00m\n\u001b[0;32m   3213\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_input_names[\u001b[39m0\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m encoded_inputs:\n\u001b[0;32m   3214\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   3215\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou should supply an encoding or a list of encodings to this method \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 3216\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthat includes \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_input_names[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, but you provided \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(encoded_inputs\u001b[39m.\u001b[39;49mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3217\u001b[0m     )\n\u001b[0;32m   3219\u001b[0m required_input \u001b[39m=\u001b[39m encoded_inputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_input_names[\u001b[39m0\u001b[39m]]\n\u001b[0;32m   3221\u001b[0m \u001b[39mif\u001b[39;00m required_input \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(required_input, Sized) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(required_input) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n","\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"]}],"source":["main(max_length= 2048, seed = 42)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPA0kXamUa9M8sSEAFQm82t","collapsed_sections":["ho0d36DW3NFc","O3YXT5Le3YZV","B9tCzXhX4awZ","eq_gQ-cn4z5g"],"mount_file_id":"1lrDAZqIgOuL0OkBPy-BDaQaD6jnY_v7r","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
